{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: <https://drive.google.com/file/d/1dfbAsM9DwA7tYhInyflIpZnYs7VT-0AQ/view> \n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "datafilename = 'WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "# Load data\n",
    "df = pd.read_csv(datafilename)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7032, 21)\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(\" \", np.NaN).dropna()\n",
    "print(df.shape)\n",
    "\n",
    "df_bak = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_male_bool(val):\n",
    "    if (val == 'Male'):\n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "def zero_one_to_0_1(val):\n",
    "    if(val == 0): \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "    \n",
    "def yes_no_to_0_1(val):\n",
    "    if(val == 'No'): \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "    \n",
    "def n_y_NIS_to_int(val):\n",
    "    if (val == 'No'):\n",
    "        return 0\n",
    "    elif (val == 'Yes'):\n",
    "        return 2\n",
    "    elif (val ==  'No internet service'):\n",
    "        return 1\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "def phone_service_to_int(val):\n",
    "    if (val == 'No'):\n",
    "        return 0\n",
    "    elif (val == 'Yes'):\n",
    "        return 2\n",
    "    elif (val ==  'No phone service'):\n",
    "        return 1\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "def Internet_service_to_int(val):\n",
    "    if (val == 'No'):\n",
    "        return 0\n",
    "    elif (val == 'DSL'):\n",
    "        return 1\n",
    "    elif (val ==  'Fiber optic'):\n",
    "        return 2\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "def Contract_to_Int(val):\n",
    "    if (val == 'Month-to-month'):\n",
    "        return 0\n",
    "    elif (val == 'One year'):\n",
    "        return 1\n",
    "    elif (val ==  'Two year'):\n",
    "        return 2\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "    \n",
    "def PaymentMethod(val):\n",
    "    if (val == 'Electronic check'):\n",
    "        return 0\n",
    "    elif (val == 'Mailed check'):\n",
    "        return 1\n",
    "    elif (val == 'Bank transfer (automatic)'):\n",
    "        return 2\n",
    "    elif (val == 'Credit card (automatic)'):\n",
    "        return 3 \n",
    "    else:\n",
    "        return \"Error\" \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bak.copy()\n",
    "def munge(df):\n",
    "    df.replace(\" \", np.NaN).dropna(inplace=True)\n",
    "\n",
    "    df['male'] = df['gender'].apply(is_male_bool)\n",
    "    \n",
    "    df['SeniorCitizen'] = df['SeniorCitizen'].apply(zero_one_to_0_1)\n",
    "    \n",
    "    for col in ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']:\n",
    "        df[col] = df[col].apply(yes_no_to_0_1)\n",
    "    \n",
    "    for col in ['DeviceProtection', 'OnlineSecurity', 'OnlineBackup','TechSupport', \n",
    "                'StreamingTV', 'StreamingMovies']:\n",
    "        df[col] = df[col].apply(n_y_NIS_to_int)\n",
    "        \n",
    "    for col in ['MultipleLines']:\n",
    "        df[col] = df[col].apply(phone_service_to_int)\n",
    "        \n",
    "    for col in ['InternetService']:\n",
    "        df[col] = df[col].apply(Internet_service_to_int)\n",
    "        \n",
    "    for col in ['Contract']:\n",
    "        df[col] = df[col].apply(Contract_to_Int)\n",
    "        \n",
    "    for col in ['PaymentMethod']:\n",
    "        df[col] = df[col].apply(PaymentMethod)\n",
    "        \n",
    "    df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "        \n",
    "    df.drop(columns=[\n",
    "                        'customerID', \n",
    "                    'gender'\n",
    "# #                      'gender', 'SeniorCitizen', 'Partner', 'Dependents'\n",
    "                        ], inplace=True) # unique, so no information\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OnlineBackup          int64\n",
       "MonthlyCharges      float64\n",
       "DeviceProtection      int64\n",
       "PaperlessBilling      int64\n",
       "StreamingMovies       int64\n",
       "MultipleLines         int64\n",
       "SeniorCitizen         int64\n",
       "PhoneService          int64\n",
       "StreamingTV           int64\n",
       "InternetService       int64\n",
       "TechSupport           int64\n",
       "OnlineSecurity        int64\n",
       "TotalCharges        float64\n",
       "tenure                int64\n",
       "Contract              int64\n",
       "Partner               int64\n",
       "Dependents            int64\n",
       "PaymentMethod         int64\n",
       "male                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_bak.copy()\n",
    "\n",
    "target = 'Churn'\n",
    "\n",
    "features = list ( set(df.columns) - {target} )\n",
    "\n",
    "input_node_count = len(features)\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_munged = munge(X)\n",
    "\n",
    "X_munged.dtypes\n",
    "# X_munged.head()\n",
    "# df.MultipleLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "7038    0\n",
       "7039    0\n",
       "7040    0\n",
       "7041    1\n",
       "7042    0\n",
       "Name: Churn, Length: 7032, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(X_munged)\n",
    "y_train, y_test = train_test_split(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# print(X_train_scaled[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1344      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,969\n",
      "Trainable params: 5,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5274 samples, validate on 1758 samples\n",
      "Epoch 1/50\n",
      "5274/5274 [==============================] - 25s 5ms/sample - loss: 2.5854 - mse: 2.5854 - mae: 0.5976 - val_loss: 0.2372 - val_mse: 0.2372 - val_mae: 0.3540\n",
      "Epoch 2/50\n",
      "5274/5274 [==============================] - 14s 3ms/sample - loss: 0.3096 - mse: 0.3096 - mae: 0.4449 - val_loss: 0.4503 - val_mse: 0.4503 - val_mae: 0.5766s: 0.2864 - mse: 0.2864\n",
      "Epoch 3/50\n",
      "5274/5274 [==============================] - 15s 3ms/sample - loss: 0.2975 - mse: 0.2975 - mae: 0.4294 - val_loss: 0.2009 - val_mse: 0.2009 - val_mae: 0.3858\n",
      "Epoch 4/50\n",
      "5274/5274 [==============================] - 14s 3ms/sample - loss: 0.3030 - mse: 0.3030 - mae: 0.4422 - val_loss: 0.2707 - val_mse: 0.2707 - val_mae: 0.3924loss: 0.3071 - mse\n",
      "Epoch 5/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.2780 - mse: 0.2780 - mae: 0.4287 - val_loss: 0.2411 - val_mse: 0.2411 - val_mae: 0.3653\n",
      "Epoch 6/50\n",
      "5274/5274 [==============================] - 15s 3ms/sample - loss: 0.2540 - mse: 0.2540 - mae: 0.4151 - val_loss: 0.2663 - val_mse: 0.2663 - val_mae: 0.4726\n",
      "Epoch 7/50\n",
      "5274/5274 [==============================] - 14s 3ms/sample - loss: 0.2251 - mse: 0.2251 - mae: 0.4013 - val_loss: 0.3000 - val_mse: 0.3000 - val_mae: 0.4154\n",
      "Epoch 8/50\n",
      "5274/5274 [==============================] - 13s 3ms/sample - loss: 0.2090 - mse: 0.2090 - mae: 0.3914 - val_loss: 0.2199 - val_mse: 0.2199 - val_mae: 0.4451\n",
      "Epoch 9/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.2053 - mse: 0.2053 - mae: 0.3889 - val_loss: 0.2064 - val_mse: 0.2064 - val_mae: 0.3698\n",
      "Epoch 10/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.2024 - mse: 0.2024 - mae: 0.3893 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.4017: 0.2052 - mse: 0.2052 - mae: 0.39 \n",
      "Epoch 11/50\n",
      "5274/5274 [==============================] - 16s 3ms/sample - loss: 0.1945 - mse: 0.1945 - mae: 0.3877 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.39330.1947 - mse: 0.1\n",
      "Epoch 12/50\n",
      "5274/5274 [==============================] - 15s 3ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3863 - val_loss: 0.2000 - val_mse: 0.2000 - val_mae: 0.4093\n",
      "Epoch 13/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3878 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.3938\n",
      "Epoch 14/50\n",
      "5274/5274 [==============================] - 15s 3ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3879 - val_loss: 0.2006 - val_mse: 0.2006 - val_mae: 0.3842: 0.1930 - mse: 0.1930 - mae: 0.384 - ETA: 4s - loss: 0.1935 - ETA: 2s - - ETA: 0s - loss: 0.1938 - mse: 0.1938 - mae: 0\n",
      "Epoch 15/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3862 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.4013\n",
      "Epoch 16/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3878 - val_loss: 0.1996 - val_mse: 0.1996 - val_mae: 0.403135 - mae: 0.387 - ETA: 2s - loss: 0.1933 - mse: 0.1933  - ETA: 1s - loss: 0.1934 - ms - ETA: 0s - loss: 0.1940 - mse: 0.1940 - mae:\n",
      "Epoch 17/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3878 - val_loss: 0.1996 - val_mse: 0.1996 - val_mae: 0.3953\n",
      "Epoch 18/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3868 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3993\n",
      "Epoch 19/50\n",
      "5274/5274 [==============================] - 16s 3ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3876 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.3923\n",
      "Epoch 20/50\n",
      "5274/5274 [==============================] - 18s 3ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3862 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.4051\n",
      "Epoch 21/50\n",
      "5274/5274 [==============================] - 14s 3ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3875 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.4000\n",
      "Epoch 22/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3877 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3968\n",
      "Epoch 23/50\n",
      "5274/5274 [==============================] - 12s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3867 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3990\n",
      "Epoch 24/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3879 - val_loss: 0.1999 - val_mse: 0.1999 - val_mae: 0.3906\n",
      "Epoch 25/50\n",
      "5274/5274 [==============================] - 13s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3877 - val_loss: 0.2011 - val_mse: 0.2011 - val_mae: 0.3810\n",
      "Epoch 26/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3867 - val_loss: 0.1996 - val_mse: 0.1996 - val_mae: 0.3959 ETA: 1s - loss: 0.1\n",
      "Epoch 27/50\n",
      "5274/5274 [==============================] - 17s 3ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3862 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.39947 - mae: 0 - ETA: \n",
      "Epoch 28/50\n",
      "5274/5274 [==============================] - 16s 3ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3885 - val_loss: 0.2007 - val_mse: 0.2007 - val_mae: 0.3836\n",
      "Epoch 29/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1943 - mse: 0.1943 - mae: 0.3867 - val_loss: 0.2004 - val_mse: 0.2004 - val_mae: 0.3859\n",
      "Epoch 30/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3871 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3999\n",
      "Epoch 31/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3872 - val_loss: 0.1998 - val_mse: 0.1998 - val_mae: 0.3916\n",
      "Epoch 32/50\n",
      "5274/5274 [==============================] - 8s 2ms/sample - loss: 0.1943 - mse: 0.1943 - mae: 0.3881 - val_loss: 0.2001 - val_mse: 0.2001 - val_mae: 0.3879\n",
      "Epoch 33/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3868 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3988\n",
      "Epoch 34/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3883 - val_loss: 0.2007 - val_mse: 0.2007 - val_mae: 0.3836\n",
      "Epoch 35/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3875 - val_loss: 0.1998 - val_mse: 0.1998 - val_mae: 0.3910\n",
      "Epoch 36/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3872 - val_loss: 0.2000 - val_mse: 0.2000 - val_mae: 0.3896\n",
      "Epoch 37/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3863 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3972\n",
      "Epoch 38/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3868 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3968\n",
      "Epoch 39/50\n",
      "5274/5274 [==============================] - 9s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3882 - val_loss: 0.2004 - val_mse: 0.2004 - val_mae: 0.3854\n",
      "Epoch 40/50\n",
      "5274/5274 [==============================] - 8s 1ms/sample - loss: 0.1937 - mse: 0.1937 - mae: 0.3885 - val_loss: 0.2039 - val_mse: 0.2039 - val_mae: 0.3694\n",
      "Epoch 41/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3835 - val_loss: 0.2010 - val_mse: 0.2010 - val_mae: 0.4162\n",
      "Epoch 42/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1941 - mse: 0.1941 - mae: 0.3884 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3979\n",
      "Epoch 43/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3882 - val_loss: 0.2002 - val_mse: 0.2002 - val_mae: 0.3877\n",
      "Epoch 44/50\n",
      "5274/5274 [==============================] - 11s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3859 - val_loss: 0.1996 - val_mse: 0.1996 - val_mae: 0.3959\n",
      "Epoch 45/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1939 - mse: 0.1939 - mae: 0.3879 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.3934\n",
      "Epoch 46/50\n",
      "5274/5274 [==============================] - 12s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3867 - val_loss: 0.1997 - val_mse: 0.1997 - val_mae: 0.3935\n",
      "Epoch 47/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1938 - mse: 0.1938 - mae: 0.3875 - val_loss: 0.2005 - val_mse: 0.2005 - val_mae: 0.3850\n",
      "Epoch 48/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1938 - mse: 0.1938 - mae: 0.3864 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3968\n",
      "Epoch 49/50\n",
      "5274/5274 [==============================] - 10s 2ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3879 - val_loss: 0.2003 - val_mse: 0.2003 - val_mae: 0.3867\n",
      "Epoch 50/50\n",
      "5274/5274 [==============================] - 8s 1ms/sample - loss: 0.1940 - mse: 0.1940 - mae: 0.3863 - val_loss: 0.1995 - val_mse: 0.1995 - val_mae: 0.3986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6834164690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important Hyperparameters\n",
    "inputs = X_train_scaled.shape[1]\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(input_node_count, input_dim=inputs, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse', 'mae'])\n",
    "\n",
    "# Fit Model\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_test, y_test), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# New model\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "# batch_size = [10, 20, 40, 60, 80, 100]\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
    "              'epochs': [20]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
